\section{What I will do}

The goal of this project is to develop, implement and evaluate for future feasibility a method for aligning large language models to a set of representatively collected human values. This will be an end-to-end project that involves using current survey data and collecting new data, aligning a large language model using different methods and evaluating the effectiveness of the alignment.

\section{What problem I will solve}

Current methods for training large language models involve scraping the internet for large amount of text data. This creates a very powerful next token prediction model. Then to turn this models into something useful for the end user (e.g. chatbots, assistants, robo doctor etc) the model is aligned to how we want it to behave. Current methods for alignment involve contracting human labelers/annotators/demonstrators to provide data to give to the model on how we want it to behave. Problematically this is a opaque process that gives the end user little insight into what the model is "designed to do". Instead we can let the public directly and indirectly decide on what values they want the model to be aligned to. More so the public as the users and recipients of the model's outputs should have a say in the way that the model behaves. Large language models are on track to become tomorrows, accountants, lawyers, doctors and more, we need to ensure that we the people are the ones who decide on what kind of people they are.

\section{Timeline}

\todo[inline]{For now I will leave the timeline uncompleted. Once I have a more concrete idea of the method I will fill this in properly. There is code left in to help with how to make a gantt chart.}

The project will be carried out over three main phases. The first phase will be the organization and clustering of existing survey data to represent human values. The second phase will be an iterative process of aligning a large language model and evaluating its performance. The third phase involves collecting specific alignment data to further refine and train the model, followed by a final evaluation.

\begin{figure}[h!]
\centering
\begin{ganttchart}[
  vgrid, hgrid,
  x unit=0.5cm
]{1}{21}

  % --- Month labels ---
  \gantttitle{Jan}{2}
  \gantttitle{Feb}{4}
  \gantttitle{Mar}{4}
  \gantttitle{Apr}{4}
  \gantttitle{May}{4}
  \gantttitle{Jun}{3} \\

  % --- Week numbers ---
  \gantttitlelist{1,...,21}{1} \\

  % --- Work packages ---
  \ganttgroup{Survey Data Analysis}{1}{3} \\
  \ganttbar{Get access to data}{1}{1} \\
  \ganttbar{Organise \& Cluster Data}{2}{3} \\

  \ganttgroup{Aligning Model}{4}{18} \\
  \ganttbar{Select Base Model}{4}{4} \\
  \ganttbar{Pilot fine tune to test pipeline}{5}{6} \\
  \ganttbar{Full fine tuning runs}{9}{10} \\
  \ganttbar{Fine tuning with collected data}{17}{18} \\
  
  \ganttgroup{Evaluating Alignment}{7}{20}\\
  \ganttbar{Create Eval Method}{7}{9} \\
  \ganttbar{Initial Evaluation}{11}{12} \\
  \ganttbar{Final Evaluation}{19}{19} \\

  \ganttgroup{Public consultation}{13}{17} \\
  \ganttbar{Design}{13}{15} \\
  \ganttbar{Collect Responses}{16}{17} \\

  \ganttgroup{Writing report}{1}{21} \\
  \ganttbar{Writeup survey data clustering}{3}{3} \\
  \ganttbar{Writeup alignment process}{9}{10} \\
  \ganttbar{Writeup Eval method}{10}{11} \\
  \ganttbar{Writeup public consultation}{17}{17} \\
  \ganttbar{Complete writeup}{19}{21} 
\end{ganttchart}

\caption{Project timeline in weeks (only roughly aligned to months). This assumes a start time of end of January 2026 with near part time work ramping up to full time work by end of February.}
\end{figure}

\section{Output}

The output is both qualitative and quantitative in nature. There are four main deliverables:

\begin{itemize}
    \item A collection of aligned LLMs with various checkpoints of just survey data and then with the collected data.
    \item A public dataset of collected data around preferred values and responses for alignment.
    \item Experimental results evaluating the effectiveness of different alignment methods using the collected data.
\end{itemize}

\section{Resources needed}

There are two resource requirements for this project, hardware and public survey responses.

\subsection{Hardware}
The first is hardware which will be needed to do the alignment finetuning evaluation of the models. For the base LLM I would want to use a model in the range of 7 billion to 30 billion parameters, as this will get me close to state of the art performance on many tasks. This means that I will need access to about 200GB of GPU memory to be able to finetune the model effectively. Each finetuning run will take in the realm of 3-6 hours depending on the size of the model, amount of data used, alignment methods used and GPU hardware. Therefore given the goal of trying a handful of methods and different value sets I estimate about \footnote{4 hours per fine tune * 3 different methods * 5 different value sets + 5 hours of evaluation = 65 hours} 70 hours of GPU time will be needed. The cost of a GPU hour on a high end GPU such as a B200 is 6 USD per hour which would make the total cost about 420 USD.
Alternatively the Engineering and Computer Science department's GPU servers should give me access to machines with around 80GB of vram. This would allow me to fine-tune smaller models in the 7-13 billion parameter range. This should still be sufficient for a proof of concept and evaluation of the alignment methods.

\subsubsection{Public consultation responses}

The idea of using the public to help align large language models is central to this project. Most of the fine tuning will be done using the survey data which can be used to get the model roughly aligned to human values. However to get more specific and granular alignment I will collect new data from the public to further refine the model's behavior. This will be in the form of an interactive survey where participants will provide some form of preference feedback on model outputs. I envision using a tool like Polis or similar to collect and aggregate responses in a meaningful way. I would expect to need at least 50 or so people from the various subgroups and for each of them to spend maybe 2-3 15 minutes blocks providing feedback on model outputs.
